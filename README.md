[![](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/donate/?hosted_button_id=58F9TDDRBND4L)

# AWS Terraform Helm Microservices PoC for Devops
This PoC shows how to use Terraform to host TLS microservices (or many) in Amazon Elastic Kubernetes Service (Amazon EKS) deployed with Helm charts. The structure of the project is below and it is the third of three cloud projects (GCP, AZ, AWS) that show how to manage microservices hosted in different cloud providers.

# Preconditions
## Create credentials, export them and use them when configuring aws 
```
aws configure
```
## Install aws-cli (using OSX here)
```
curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg"
sudo installer -pkg AWSCLIV2.pkg -target /
aws --version
```
## Install
```
brew tap weaveworks/tap
brew install weaveworks/tap/eksctl
```

## Terraform

- Confirm that you are using the expected credentials:
```
aws sts get-caller-identity
```
- Create the S3 bucket to persist terraform
```
aws s3api create-bucket --bucket ms-terraform-state1 --region eu-north-1 --create-bucket-configuration LocationConstraint=eu-north-1
```
- A Dynamo table must be created for terraform state locking
```
aws dynamodb create-table \
    --table-name ms-terraform-state1 \
    --attribute-definitions AttributeName=LockID,AttributeType=S \
    --key-schema AttributeName=LockID,KeyType=HASH \
    --billing-mode PAY_PER_REQUEST \
    --region eu-north-1
```
- Ensure that the bucket was created and is accessible under the identity specified by the credentials file:
```
aws s3 ls
```

- List all terraform files and their content
```
find ./ -type f -name "*.tf" -not -path '*.terraform*' -exec sh -c 'echo "File: {}"; cat {}' \;
```
- List all terraform configuration file names and specific content if found in any of them
find ./ -type f -name "*.tf" -not -path '*.terraform*' -exec sh -c 'echo "File: {}"; cat {}' \; | grep -E "\.tf|provider.*kubernetes"
```
- Set terraform log level as needed
```
export TF_LOG=INFO
export TF_LOG=TRACE
```

- Create and apply terraform plan
```
cd terraform
export TF_LOG=INFO; export KUBE_CONFIG_PATH=~/.kube/config && terraform init && terraform validate && terraform plan -out=tfplan && terraform apply "tfplan"
```

## kubernetes access
- Check cluster status:
```
aws eks --region eu-north-1 list-clusters
aws eks --region eu-north-1 describe-cluster --name cluster1
aws eks --region eu-north-1 list-nodegroups --cluster-name cluster1 
```
- Authorize kubectl to access the cluster 
```
aws eks --region eu-north-1 update-kubeconfig --name cluster1
```
- Add the current AWS IAM account an IAM access entry with permissions to access the cluster by going to the cluster from the AWS console, access tab, create access entry, select the ARN of your principal (you can search for it in the dropdown or see it from CLI with command aws sts get-caller-identity), next, add access policy, select AmazonEKSAdminPolicy, next, create and go back to the access tab, click on the access entry you added for your user ARN, add access policy, select AmazonEKSClusterAdminPolicy.
- Find out users and roles with access to the kubernetes cluster
```
kubectl describe configmap -n kube-system aws-auth 
``` 
- Install thei AWS Load Balancer controller
```
./deploy-aws-load-balancer-controller.sh cluster1
```
- Authenticate docker client to work with AWS ECR
```
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query "Account" --output text)
AWS_REGION=$(aws configure get region)
aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com
```
- Deploy via helm a microservice named "microservice#" where # is the major version which keeps support for that particular release which usees the TLS certificate for the domain, previously generated by terraform. The api-ingress.yaml will create an ALB if it does not exist. It is this ALB which we need to use to create the A record for the domain in Route53.
```
./deploy.sh ./deploy.sh default test2.nestorurquiza.com microservice1 1.0.0
```
- Extract the ALB address from the ingress. If you ever remove all ingresses for the same group , then you must repeat this step
```
GROUP_NAME=$(grep 'alb.ingress.kubernetes.io/group.name' helm/templates/api-ingress.yaml | awk -F'"' '{print $2}'); kubectl get ingress -A -o json | jq -r --arg GROUP_NAME "$GROUP_NAME" '.items[] | select(.metadata.annotations."alb.ingress.kubernetes.io/group.name"==$GROUP_NAME).status.loadBalancer.ingress[].hostname' | head -1
```
- Use the ALB address to create the A record for the domain:
```
./add-a-record-for-alb.sh <ALB_ADDRESS> test2.nestorurquiza.com nestorurquiza.com
```
- List all yaml files (mostly used from helm)
```
find ./ -type f -name "*.yaml" -exec sh -c 'echo "File: {}"; cat {}' \;
```
- Test the app responds on port 8080 in the deployed pods
```
kubectl exec -ti $(kubectl get pods | grep -o 'microservice[^ ]*' | head -1) -- curl localhost:8080
```
- Test the app responds on port 80 in the deployed service
```
kubectl port-forward svc/microservice1-1 8080:80 & sleep 5 && curl localhost:8080
```
- Test the app from the ALB external endpoint
```
export EXPECTED_API_KEY='2f5ae96c-b558-4c7b-a590-a501ae1c3f6c' && export HOST=test2.nestorurquiza.com && curl -kX POST -H "X-Parse-REST-API-Key: ${EXPECTED_API_KEY}" -H "Content-Type: application/json" -d '{ "message": "This is a test", "to": "Juan Perez", "from": "Rita Asturia", "timeToLifeSec": 45 }' http://${HOST}/api/microservice1/v1/DevOps
```
 
## Services SDLC
Whether you are maintaining a monolith or multiple microservices you have to handle API versions. Here is one way to handle that.

- Branch microservice version 1
```
git checkout -b microservice-1
git push -u origin microservice-1
```
- To switch to microservice version 1 and merge new code from branch into it
```
git branch
git checkout microservice-1
git merge main
git push
```
- Branch microservice-2
Our original app code will be changed in this branch so when deployed we can see how the two microservices are isolated from each other.
```
git checkout -b microservice-2
git push -u origin microservice-2
```
- To switch to microservice version 2 and merge new code from branch into it
```
git branch
git checkout microservices-2
git merge main
git push
```
- Make the change to microservices-2, commit and push
```
git add .
git commit -m "message for microservice changed in versiuon 2"
git push
```

- The difference between the two branches is below:
```
nu@Nestors-MacBook-Air aws-microservices-poc % git diff microservice-1..microservice-2
... 
-    response_message = f"Hello {sender_name}, your message will be sent."
+    response_message = f"Hello {sender_name}, your message will be sent to {receiver_name}."
...
```
- Deploy microservices from their proper branches
```
git checkout microservice-1 && git pull; git branch && ./deploy.sh default test2.nestorurquiza.com microservice1 1.0.3
git checkout microservice-2 && git pull; git branch && ./deploy.sh default test2.nestorurquiza.com microservice2 2.0.2
```

### Release
Releasing is the process of tagging and registering the status of such tag like whether tests pass or not. TODO: Add a release.sh script that will check any new tag in valid branches and deploy the specific version with deploy.sh.

### Testing
End to end Testing should be triggered when any new microservice is deployed but API releated e2e tests for the specific microservice should be triggered first and if those pass you might want to push the microservice new version to prod.

### API version management
Adding a new version of a microservice and using that version from multiple other microservices or UIs is serious business. Logging aggregation, metrics, thressholds and many more SRE concerns have to be considered. Microservices can reduce delivery time significantly but the investment is not little.

### SDLC recommendations
1. Start from main branch
2. Once you get a v1 that is good enough then create a branch out of it
3. release (tag) v1 branch
4. Keep working on v1 for any fixes needed
5. Use git cherry-pick to select what to merge from v1 code to main branch every time it is tagged as well as collect changes from other branches into v1
6. When a new feature demands a new branch, create it out of the main branch into v2, v3 etc. branches
7. Organizing this requires a lot of transaction costs, which is one of the disadvantages of this modus operandi versus handling all versions at the app layer (treating each microservice as a monolith).
8. Have a deprecation policy for each version.
